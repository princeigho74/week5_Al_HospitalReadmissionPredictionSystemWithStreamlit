# Hospital Readmission Prediction System

AI-powered clinical decision support system for predicting 30-day hospital readmission risk.

## ğŸ‘¨â€ğŸ’» Developer
**Happy Igho Umukoro**  
ğŸ“§ princeigho74@gmail.com  
ğŸ“± +2348065292102

## ğŸ“‹ Project Overview
This repository contains the complete implementation of a machine learning system to predict patient readmission within 30 days of hospital discharge. The system prioritizes interpretability, fairness, and HIPAA compliance.

## âœ¨ Key Features
- Logistic regression model with 80% recall
- Fairness-aware design with demographic parity monitoring
- HIPAA-compliant data handling
- Real-time API for clinical integration
- Comprehensive bias detection and mitigation

## ğŸš€ Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/hospital-readmission-prediction.git
cd hospital-readmission-prediction

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## ğŸ“ Repository Structure

```
hospital-readmission-prediction/
â”‚
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Original data (not in repo if PHI)
â”‚   â”œâ”€â”€ processed/                    # Cleaned, de-identified data
â”‚   â””â”€â”€ synthetic/                    # Synthetic data for demonstration
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â”œâ”€â”€ 04_evaluation_fairness.ipynb
â”‚   â””â”€â”€ 05_interpretation.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ data_loader.py           # Data extraction functions
â”‚   â”‚   â””â”€â”€ preprocessor.py          # Preprocessing pipeline
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ feature_engineering.py   # Feature creation functions
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train.py                 # Model training scripts
â”‚   â”‚   â””â”€â”€ predict.py               # Inference functions
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.py               # Evaluation metrics
â”‚   â”‚   â””â”€â”€ fairness_audit.py        # Bias detection
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ helpers.py               # Utility functions
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_fairness.py
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ app.py                   # Flask/FastAPI application
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ monitoring/
â”‚       â””â”€â”€ drift_detection.py
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ data_dictionary.md
â”‚   â”œâ”€â”€ model_card.md                # Model documentation
â”‚   â””â”€â”€ fairness_report.md
â”‚
â””â”€â”€ reports/
    â””â”€â”€ figures/                      # Visualizations for report
```

## ğŸ”§ Quick Start

### Training the Model
```python
from src.data.preprocessor import ReadmissionPreprocessor
from src.models.train import ReadmissionModelTrainer

# Load and preprocess data
preprocessor = ReadmissionPreprocessor()
X_train, y_train = preprocessor.fit_transform(train_data)

# Train model
trainer = ReadmissionModelTrainer()
model = trainer.train(X_train, y_train)
trainer.save_model('models/readmission_model.pkl')
```

### Making Predictions
```python
from src.models.predict import ReadmissionPredictor

# Initialize predictor
predictor = ReadmissionPredictor()

# Make prediction
risk_score, risk_category, factors = predictor.predict(patient_data)
print(f"Readmission Risk: {risk_score:.1f}%")
print(f"Category: {risk_category}")
```

### Running the API
```bash
cd src/deployment/api
python app.py
```

## ğŸ“Š Model Performance

- **Accuracy:** 82%
- **Precision:** 57%
- **Recall:** 80%
- **F1-Score:** 0.67
- **ROC-AUC:** 0.85
- **Fairness:** Disparate Impact Ratio = 0.82

## ğŸ›¡ï¸ Fairness & Ethics

This model includes comprehensive fairness monitoring:
- Demographic parity tracking
- Equalized odds validation
- Regular bias audits
- Patient privacy protection (HIPAA compliant)

See `docs/fairness_report.md` for detailed analysis.

## ğŸ“– Documentation

- [Data Dictionary](docs/data_dictionary.md) - Description of all features
- [Model Card](docs/model_card.md) - Complete model documentation
- [Fairness Report](docs/fairness_report.md) - Bias analysis and mitigation

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run specific test file
pytest tests/test_preprocessing.py

# Run with coverage
pytest --cov=src tests/
```

## ğŸš€ Deployment

The model is deployed as a REST API that integrates with hospital EHR systems:

1. **API Endpoint:** `/predict`
2. **Authentication:** OAuth 2.0
3. **Response Time:** < 500ms
4. **Availability:** 99.9% uptime

See `deployment/api/README.md` for deployment instructions.

## ğŸ“ˆ Monitoring

Continuous monitoring includes:
- Performance metrics tracking
- Concept drift detection
- Fairness degradation alerts
- Automated retraining triggers

## ğŸ¤ Contributing

This is an academic project. For questions or suggestions:
- Email: princeigho74@gmail.com
- Phone: +2348065292102

## ğŸ“„ License

MIT License - See LICENSE file for details.

## ğŸ™ Acknowledgments

- Based on AI Development Workflow assignment
- Developed by Happy Igho Umukoro - November 2025
- Healthcare AI best practices from Anthropic, OpenAI, and FDA guidelines

## ğŸ“š References

1. Obermeyer et al. (2019) - "Dissecting racial bias in healthcare algorithms"
2. Rajkomar et al. (2019) - "Machine learning in medicine"
3. Kansagara et al. (2011) - "Risk prediction models for hospital readmission"

---

**Last Updated:** November 4, 2025  
**Version:** 1.0.0  
**Developer:** Happy Igho Umukoro
